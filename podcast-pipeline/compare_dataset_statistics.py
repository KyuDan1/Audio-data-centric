#!/usr/bin/env python3
"""
Full-Duplex ë°ì´í„°ì…‹ ìƒì„¸ í†µê³„ ë° ìŒì„± í’ˆì§ˆ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ (Final Fixed Version)

[ì£¼ìš” ê¸°ëŠ¥]
1. .opus, .ogg, .wav, .mp3 ë“± ë‹¤ì–‘í•œ ì˜¤ë””ì˜¤ í¬ë§· ìë™ ê°ì§€
2. soundfile ì‹¤íŒ¨ ì‹œ librosaë¥¼ í†µí•œ ê°•ì œ ë¡œë“œ ì§€ì› (Opus í˜¸í™˜ì„± í•´ê²°)
3. SNR, Clipping, RMS, Speaker Entropy, Overlap Duration ë“± ì‹¬ì¸µ ë¶„ì„
"""

import os
import json
import subprocess
import numpy as np
import pandas as pd
import soundfile as sf
import librosa
from pathlib import Path
from tqdm import tqdm
from collections import defaultdict
import argparse
from datetime import datetime
import warnings
import math

warnings.filterwarnings('ignore')

# =============================================================================
# [ì„¤ì •] ê²½ë¡œë¥¼ ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”
# =============================================================================
ORIGINAL_ROOT = "/mnt/ddn/kyudan/DATASET/podcast_rss_feeds/podcasts_chunk_0"
PREPROCESSED_ROOT = "/mnt/ddn/kyudan/DATASET/podcast_rss_feeds/preprocessed_audio"

def get_audio_duration(audio_path):
    """ffprobeë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê¸¸ì´ë¥¼ ë¹ ë¥´ê²Œ êµ¬í•©ë‹ˆë‹¤."""
    try:
        cmd = [
            'ffprobe', '-v', 'error',
            '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1',
            str(audio_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
        if result.returncode == 0 and result.stdout.strip():
            return float(result.stdout.strip())
    except Exception:
        pass
    return None

def calculate_speaker_entropy(segments, total_duration):
    """í™”ì ë°œí™” ê· í˜•ë„ (Shannon Entropy): 1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê· ë“±í•œ ëŒ€í™”"""
    if not segments or total_duration == 0:
        return 0.0
    
    speaker_durations = defaultdict(float)
    for seg in segments:
        dur = seg['end'] - seg['start']
        speaker_durations[seg['speaker']] += dur
        
    probs = [d / total_duration for d in speaker_durations.values() if d > 0]
    
    if len(probs) <= 1:
        return 0.0
        
    entropy = -sum(p * math.log(p) for p in probs)
    max_entropy = math.log(len(probs))
    
    return entropy / max_entropy if max_entropy > 0 else 0.0

def analyze_signal_from_array(y, sr, segments):
    """ë¡œë“œëœ ì˜¤ë””ì˜¤ ë°°ì—´(y)ì„ ê¸°ë°˜ìœ¼ë¡œ í’ˆì§ˆ ì§€í‘œ ê³„ì‚°"""
    try:
        # Stereo -> Mono ë³€í™˜
        if len(y.shape) > 1:
            y = np.mean(y, axis=1)
            
        # 1. Clipping Rate (0.99 ì´ìƒì¸ ìƒ˜í”Œ ë¹„ìœ¨)
        clipping_threshold = 0.99
        clipping_rate = np.mean(np.abs(y) >= clipping_threshold) * 100
        
        # 2. RMS (Loudness)
        rms = np.sqrt(np.mean(y**2))
        
        # 3. SNR (Signal-to-Noise Ratio)
        mask = np.zeros_like(y, dtype=bool)
        for seg in segments:
            start_sample = int(seg['start'] * sr)
            end_sample = int(seg['end'] * sr)
            end_sample = min(end_sample, len(y))
            if start_sample < len(y):
                mask[start_sample:end_sample] = True
            
        speech_power = np.mean(y[mask]**2) if np.any(mask) else 1e-9
        noise_power = np.mean(y[~mask]**2) if np.any(~mask) else 1e-9
        
        if noise_power < 1e-9: noise_power = 1e-9
        if speech_power < 1e-9: speech_power = 1e-9

        snr = 10 * np.log10(speech_power / noise_power)
        
        return {
            'snr': snr,
            'clipping_rate': clipping_rate,
            'rms': rms,
            'has_audio': True
        }
    except Exception as e:
        return {'snr': np.nan, 'clipping_rate': np.nan, 'rms': np.nan, 'has_audio': False}

def analyze_audio_file(audio_path, segments):
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ í’ˆì§ˆì„ ë¶„ì„í•©ë‹ˆë‹¤.
    soundfile(ë¹ ë¦„)ì„ ë¨¼ì € ì‹œë„í•˜ê³ , ì‹¤íŒ¨ ì‹œ librosa(í˜¸í™˜ì„± ì¢‹ìŒ)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        # 1ì°¨ ì‹œë„: soundfile (WAV, FLAC ë“±)
        y, sr = sf.read(str(audio_path))
        return analyze_signal_from_array(y, sr, segments)
    except Exception:
        try:
            # 2ì°¨ ì‹œë„: librosa (Opus, MP3, Ogg ë“± ffmpeg ë°±ì—”ë“œ ì‚¬ìš©)
            # sr=Noneìœ¼ë¡œ ì›ë³¸ ìƒ˜í”Œë§ ë ˆì´íŠ¸ ìœ ì§€
            y, sr = librosa.load(str(audio_path), sr=None)
            return analyze_signal_from_array(y, sr, segments)
        except Exception:
            # ë¡œë“œ ì‹¤íŒ¨
            return {'snr': np.nan, 'clipping_rate': np.nan, 'rms': np.nan, 'has_audio': False}

def calculate_overlap_details(segments):
    """Overlap Ratio ë° ê°œë³„ Overlap êµ¬ê°„ ê¸¸ì´ ë¶„í¬ ê³„ì‚°"""
    if len(segments) < 2:
        return 0.0, []

    total_duration = max(seg['end'] for seg in segments) - min(seg['start'] for seg in segments)
    if total_duration == 0:
        return 0.0, []

    overlap_durations = []
    sorted_segs = sorted(segments, key=lambda x: x['start'])
    
    for i, seg1 in enumerate(sorted_segs):
        for seg2 in sorted_segs[i+1:]:
            if seg2['start'] >= seg1['end']:
                break
            
            overlap_start = max(seg1['start'], seg2['start'])
            overlap_end = min(seg1['end'], seg2['end'])
            
            if overlap_start < overlap_end:
                dur = overlap_end - overlap_start
                overlap_durations.append(dur)

    total_overlap = sum(overlap_durations)
    ratio = total_overlap / total_duration if total_duration > 0 else 0
    
    return ratio, overlap_durations

def calculate_turn_taking_gaps(segments):
    """Turn-taking Gap ê³„ì‚°"""
    if len(segments) < 2:
        return []

    sorted_segments = sorted(segments, key=lambda x: x['start'])
    gaps = []

    for i in range(len(sorted_segments) - 1):
        current = sorted_segments[i]
        next_seg = sorted_segments[i + 1]

        if current['speaker'] != next_seg['speaker']:
            gap = next_seg['start'] - current['end']
            gaps.append(gap)

    return gaps

def calculate_silence_ratio(segments, total_duration):
    if total_duration == 0: return 0.0
    covered_intervals = sorted([(seg['start'], seg['end']) for seg in segments])
    if not covered_intervals: return 1.0

    merged = [covered_intervals[0]]
    for current in covered_intervals[1:]:
        prev_start, prev_end = merged[-1]
        curr_start, curr_end = current
        if curr_start <= prev_end:
            merged[-1] = (prev_start, max(prev_end, curr_end))
        else:
            merged.append(current)

    speech_duration = sum(end - start for start, end in merged)
    silence_duration = total_duration - speech_duration
    return max(0.0, silence_duration / total_duration)

def collect_preprocessed_data_stats(root_dir, sample_size=None, check_audio_quality=True):
    print("\nğŸ“Š Collecting preprocessed data & quality stats...")

    json_files = []
    for dirpath, dirnames, filenames in os.walk(root_dir):
        for filename in filenames:
            if filename.endswith('.json') and filename != 'original_paths.json':
                json_files.append(os.path.join(dirpath, filename))

    if sample_size:
        import random
        json_files = random.sample(json_files, min(sample_size, len(json_files)))
        print(f"Sampling {len(json_files)} episodes")

    podcast_stats = defaultdict(lambda: {
        'episodes': [],
        'total_duration': 0.0,
        'total_utterances': 0,
        'sum_snr': 0.0,
        'sum_clipping': 0.0,
        'count_audio_checked': 0
    })

    global_overlap_durations = []
    global_turn_gaps = []

    # ì˜¤ë””ì˜¤ í¬ë§· ìš°ì„ ìˆœìœ„
    AUDIO_EXTENSIONS = ['.opus', '.ogg', '.wav', '.mp3', '.flac', '.m4a']

    for json_path in tqdm(json_files, desc="Processing episodes"):
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except:
            continue

        metadata = data.get('metadata', {})
        segments = data.get('segments', [])
        if not segments: continue

        rel_path = os.path.relpath(json_path, root_dir)
        podcast_name = rel_path.split(os.sep)[0]
        
        # 1. Basic Stats
        total_duration = metadata.get('audio_duration_seconds', 0)
        total_utterances = len(segments)
        
        # 2. Dynamics
        overlap_ratio, overlap_durs = calculate_overlap_details(segments)
        global_overlap_durations.extend(overlap_durs)
        
        turn_gaps = calculate_turn_taking_gaps(segments)
        global_turn_gaps.extend(turn_gaps)
        
        silence_ratio = calculate_silence_ratio(segments, total_duration)
        speaker_entropy = calculate_speaker_entropy(segments, total_duration)
        speaker_count = len(set(seg['speaker'] for seg in segments if 'speaker' in seg))

        # 3. Audio Quality
        quality_metrics = {'snr': np.nan, 'clipping_rate': np.nan, 'rms': np.nan}
        
        if check_audio_quality:
            base_path = Path(json_path).with_suffix('')
            audio_found = False
            
            # í™•ì¥ì ìˆœíšŒí•˜ë©° íŒŒì¼ ì°¾ê¸°
            for ext in AUDIO_EXTENSIONS:
                candidate = base_path.with_suffix(ext)
                if candidate.exists():
                    # íŒŒì¼ ì°¾ìŒ -> ë¶„ì„ ì‹œë„
                    quality_metrics = analyze_audio_file(candidate, segments)
                    if quality_metrics['has_audio']:
                        audio_found = True
                        break
            
            # ê°™ì€ í´ë”ì— ì—†ìœ¼ë©´ 'original_path' ì°¸ì¡° ì‹œë„ (ì˜µì…˜)
            if not audio_found and 'original_path' in metadata:
                 # ë©”íƒ€ë°ì´í„°ì— ì›ë³¸ ê²½ë¡œê°€ ìˆë‹¤ë©´ ì‹œë„í•´ë³¼ ìˆ˜ ìˆìŒ (í•„ìš” ì‹œ êµ¬í˜„)
                 pass

        episode_stats = {
            'name': Path(json_path).stem,
            'duration': total_duration,
            'speakers': speaker_count,
            'speaker_entropy': speaker_entropy,
            'overlap_ratio': overlap_ratio,
            'avg_overlap_duration': np.mean(overlap_durs) if overlap_durs else 0,
            'silence_ratio': silence_ratio,
            'snr': quality_metrics['snr'],
            'clipping_rate': quality_metrics['clipping_rate'],
            'rms': quality_metrics['rms']
        }

        podcast_stats[podcast_name]['episodes'].append(episode_stats)
        podcast_stats[podcast_name]['total_duration'] += total_duration
        podcast_stats[podcast_name]['total_utterances'] += total_utterances

    return dict(podcast_stats), global_overlap_durations, global_turn_gaps

def aggregate_statistics(preprocessed_stats):
    print("\nğŸ“ˆ Aggregating statistics...")
    results = []
    
    for podcast_name, data in preprocessed_stats.items():
        episodes = data.get('episodes', [])
        if not episodes: continue
        
        def get_valid_mean(key):
            vals = [e[key] for e in episodes if not np.isnan(e.get(key, np.nan))]
            return np.mean(vals) if vals else 0.0

        row = {
            'podcast_name': podcast_name,
            'episodes': len(episodes),
            'total_hours': data['total_duration'] / 3600,
            'avg_speaker_entropy': get_valid_mean('speaker_entropy'),
            'avg_overlap_ratio': get_valid_mean('overlap_ratio'),
            'avg_overlap_duration': get_valid_mean('avg_overlap_duration'),
            'avg_silence_ratio': get_valid_mean('silence_ratio'),
            'avg_snr_db': get_valid_mean('snr'),
            'avg_clipping_rate': get_valid_mean('clipping_rate'),
            'avg_rms': get_valid_mean('rms')
        }
        results.append(row)
        
    return pd.DataFrame(results)

def main():
    parser = argparse.ArgumentParser(description="Full-Duplex Dataset Analyzer")
    parser.add_argument('--output-dir', default='comparison_statistics', help='Output Directory')
    parser.add_argument('--sample-episodes', type=int, help='Limit number of episodes for testing')
    parser.add_argument('--no-quality', action='store_true', help='Skip slow audio quality checks')
    args = parser.parse_args()

    os.makedirs(args.output_dir, exist_ok=True)
    
    print("="*70)
    print("ğŸ™ï¸ Full-Duplex Dataset Statistics & Quality Check")
    print(f"Target Directory: {PREPROCESSED_ROOT}")
    print("="*70)

    # 1. Collect Stats
    prep_stats, global_overlaps, global_gaps = collect_preprocessed_data_stats(
        PREPROCESSED_ROOT, 
        sample_size=args.sample_episodes,
        check_audio_quality=not args.no_quality
    )
    
    # 2. Aggregate
    df = aggregate_statistics(prep_stats)
    
    if df.empty:
        print("âŒ No data found.")
        return

    # 3. Save Results
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    csv_path = os.path.join(args.output_dir, f'full_stats_{timestamp}.csv')
    df.to_csv(csv_path, index=False)
    
    # Save Distributions (JSON)
    dist_stats = {
        'overlap_duration': {
            'mean': float(np.mean(global_overlaps)) if global_overlaps else 0,
            'median': float(np.median(global_overlaps)) if global_overlaps else 0,
            'p90': float(np.percentile(global_overlaps, 90)) if global_overlaps else 0,
        },
        'turn_gaps': {
            'mean': float(np.mean(global_gaps)) if global_gaps else 0,
            'median': float(np.median(global_gaps)) if global_gaps else 0,
        }
    }
    with open(os.path.join(args.output_dir, f'distributions_{timestamp}.json'), 'w') as f:
        json.dump(dist_stats, f, indent=2)

    # 4. Print Summary Report
    print("\n" + "="*70)
    print("ğŸ“Š DATASET SUMMARY REPORT")
    print("="*70)
    print(f"â€¢ Total Podcasts      : {len(df)}")
    print(f"â€¢ Total Episodes      : {df['episodes'].sum()}")
    print(f"â€¢ Total Duration      : {df['total_hours'].sum():.2f} hours")
    
    print("\n[ğŸ—£ï¸ Conversational Dynamics]")
    print(f"â€¢ Avg Speaker Entropy : {df['avg_speaker_entropy'].mean():.3f} (closer to 1.0 is better)")
    print(f"â€¢ Avg Overlap Ratio   : {df['avg_overlap_ratio'].mean()*100:.2f} %")
    print(f"â€¢ Avg Overlap Length  : {df['avg_overlap_duration'].mean():.3f} sec")
    print(f"â€¢ Avg Silence Ratio   : {df['avg_silence_ratio'].mean()*100:.2f} %")

    if not args.no_quality:
        print("\n[ğŸ”Š Audio Quality]")
        print(f"â€¢ Avg SNR             : {df['avg_snr_db'].mean():.2f} dB")
        print(f"â€¢ Avg Clipping Rate   : {df['avg_clipping_rate'].mean():.4f} %")
        print(f"â€¢ Avg Loudness (RMS)  : {df['avg_rms'].mean():.4f}")
    
    print("="*70)
    print(f"âœ“ Results saved to {csv_path}")

if __name__ == "__main__":
    main()